{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPIJ09xHL4KFrzr9ZD+256",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush-030/Mentora-Matching-Optimization/blob/main/notebook/Mentora_Matching_Algorithm_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mentora – Matching Algorithm Optimization\n",
        "\n",
        "## Problem Statement\n",
        "The original Mentora matching algorithm is a rule-based, keyword overlap system\n",
        "used to match students with faculty, industry mentors, and projects based on skills\n",
        "and interests.\n",
        "\n",
        "While fast and explainable, this baseline approach fails to capture semantic similarity\n",
        "(e.g., \"ML\" vs \"Machine Learning\"), leading to poor match quality in realistic scenarios.\n",
        "\n",
        "This notebook:\n",
        "1. Computes baseline matching performance using the existing algorithm\n",
        "2. Introduces an optimized semantic matching approach using embeddings (LLM-assisted)\n",
        "3. Compares both approaches on dummy data\n",
        "4. Quantifies the performance lift achieved\n"
      ],
      "metadata": {
        "id": "xyZTQjLAUNtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Existing Baseling Version (Code)"
      ],
      "metadata": {
        "id": "Xj60oSdQr7-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core imports\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "eWSvY1hAURXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Student Profiles\n",
        "\n",
        "students = [\n",
        "    {\n",
        "        \"id\": \"S1\",\n",
        "        \"skills\": [\"Python\", \"ML\", \"React\"],\n",
        "        \"interests\": [\"AI\", \"Healthcare\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"S2\",\n",
        "        \"skills\": [\"Java\", \"Spring\", \"SQL\"],\n",
        "        \"interests\": [\"Backend Systems\", \"Databases\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"S3\",\n",
        "        \"skills\": [\"C++\", \"Data Structures\", \"Algorithms\"],\n",
        "        \"interests\": [\"Competitive Programming\", \"Optimization\"]\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "iMF6Nok-Ucxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Faculty Profiles\n",
        "\n",
        "faculty = [\n",
        "    {\n",
        "        \"id\": \"F1\",\n",
        "        \"expertise\": [\"Machine Learning\", \"Deep Learning\", \"Python\"],\n",
        "        \"research_areas\": [\"Artificial Intelligence\", \"Medical AI\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"F2\",\n",
        "        \"expertise\": [\"Java\", \"Distributed Systems\"],\n",
        "        \"research_areas\": [\"Backend Architecture\", \"Scalable Databases\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"F3\",\n",
        "        \"expertise\": [\"Algorithms\", \"C++\"],\n",
        "        \"research_areas\": [\"Competitive Programming\", \"Graph Theory\"]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "4Gwajc_CUnbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "students, faculty"
      ],
      "metadata": {
        "id": "sm4klEUzUvBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Existing Logic (Baseline Matching Function)\n",
        "def calc_match_percent(set1, set2):\n",
        "    set1 = set(s.lower().strip() for s in (set1 or []) if s)\n",
        "    set2 = set(s.lower().strip() for s in (set2 or []) if s)\n",
        "    if not set1 or not set2:\n",
        "        return 0\n",
        "    overlap = set1 & set2\n",
        "    if not overlap:\n",
        "        return 0\n",
        "    score = round((len(overlap) / max(len(set1), len(set2))) * 100)\n",
        "    return score\n",
        "\n",
        "\n",
        "def student_to_faculty_baseline(student_profile, faculty_profile):\n",
        "    skills_score = calc_match_percent(\n",
        "        student_profile.get(\"skills\", []),\n",
        "        faculty_profile.get(\"expertise\", [])\n",
        "    )\n",
        "    interests_score = calc_match_percent(\n",
        "        student_profile.get(\"interests\", []),\n",
        "        faculty_profile.get(\"research_areas\", [])\n",
        "    )\n",
        "\n",
        "    return round((skills_score + interests_score) / 2)"
      ],
      "metadata": {
        "id": "f6MTj_4bUzSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Function results\n",
        "baseline_results = []\n",
        "\n",
        "for s in students:\n",
        "    for f in faculty:\n",
        "        score = student_to_faculty_baseline(s, f)\n",
        "        baseline_results.append({\n",
        "            \"student_id\": s[\"id\"],\n",
        "            \"faculty_id\": f[\"id\"],\n",
        "            \"baseline_score\": score\n",
        "        })\n",
        "\n",
        "baseline_df = pd.DataFrame(baseline_results)\n",
        "baseline_df"
      ],
      "metadata": {
        "id": "VHDntBzkVGq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Matching Results – Analysis\n",
        "\n",
        "The baseline matching algorithm relies on exact keyword overlap between skills\n",
        "and interests.\n",
        "\n",
        "### Observations:\n",
        "- Strong semantic matches such as:\n",
        "  - \"ML\" vs \"Machine Learning\"\n",
        "  - \"AI\" vs \"Artificial Intelligence\"\n",
        "  are not captured.\n",
        "- This leads to low scores even for human-obvious strong matches.\n",
        "- Exact matches (e.g., C++ + Algorithms) perform well.\n",
        "\n",
        "### Conclusion:\n",
        "While the baseline approach is fast and interpretable, it lacks semantic\n",
        "understanding and fails in realistic academic matching scenarios.\n"
      ],
      "metadata": {
        "id": "ER2tqUCqYJ7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now moving to the optimized version (Code)"
      ],
      "metadata": {
        "id": "W2c7jX6er2FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we move to optimization, we’ll use Sentence Transformers\n",
        "# Install Semantic Embedding Library\n",
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "J4nVpch6Vcuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Embedding Model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Loading a lightweight semantic embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "fhI7DEysl2YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we'll write the Semantic Matching Utility Function\n",
        "def semantic_match(list1, list2):\n",
        "    if not list1 or not list2:\n",
        "        return 0\n",
        "\n",
        "    embeddings_1 = model.encode(list1)\n",
        "    embeddings_2 = model.encode(list2)\n",
        "\n",
        "    similarity_matrix = cosine_similarity(embeddings_1, embeddings_2)\n",
        "\n",
        "    # Take the best semantic match\n",
        "    max_similarity = similarity_matrix.max()\n",
        "\n",
        "    return round(float(max_similarity) * 100)"
      ],
      "metadata": {
        "id": "UH4NMCSNmLQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Student to Faculty Matching\n",
        "def student_to_faculty_optimized(student_profile, faculty_profile):\n",
        "    skill_score = semantic_match(\n",
        "        student_profile.get(\"skills\", []),\n",
        "        faculty_profile.get(\"expertise\", [])\n",
        "    )\n",
        "\n",
        "    interest_score = semantic_match(\n",
        "        student_profile.get(\"interests\", []),\n",
        "        faculty_profile.get(\"research_areas\", [])\n",
        "    )\n",
        "\n",
        "    # Weighted scoring (skills more important)\n",
        "    final_score = round(0.7 * skill_score + 0.3 * interest_score)\n",
        "\n",
        "    return final_score"
      ],
      "metadata": {
        "id": "_fsgem4rmxmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Optimized Results\n",
        "optimized_results = []\n",
        "\n",
        "for s in students:\n",
        "    for f in faculty:\n",
        "        score = student_to_faculty_optimized(s, f)\n",
        "        optimized_results.append({\n",
        "            \"student_id\": s[\"id\"],\n",
        "            \"faculty_id\": f[\"id\"],\n",
        "            \"optimized_score\": score\n",
        "        })\n",
        "\n",
        "optimized_df = pd.DataFrame(optimized_results)\n",
        "optimized_df"
      ],
      "metadata": {
        "id": "OYlnhLUinJ-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging Baseline & Optimized Results\n",
        "comparison_df = baseline_df.merge(\n",
        "    optimized_df,\n",
        "    on=[\"student_id\", \"faculty_id\"]\n",
        ")\n",
        "\n",
        "comparison_df"
      ],
      "metadata": {
        "id": "ogLhZQ8EnaXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Quantitative Lift\n",
        "\n",
        "# Calculating absolute and relative improvement\n",
        "comparison_df[\"absolute_lift\"] = (\n",
        "    comparison_df[\"optimized_score\"] - comparison_df[\"baseline_score\"]\n",
        ")\n",
        "\n",
        "comparison_df[\"relative_lift_percent\"] = comparison_df.apply(\n",
        "    lambda row: round(\n",
        "        (row[\"absolute_lift\"] / row[\"baseline_score\"]) * 100, 2\n",
        "    ) if row[\"baseline_score\"] > 0 else None,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "comparison_df"
      ],
      "metadata": {
        "id": "pwwivoOJnwkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate Performance Metrics\n",
        "summary_metrics = {\n",
        "    \"Average Baseline Score\": round(comparison_df[\"baseline_score\"].mean(), 2),\n",
        "    \"Average Optimized Score\": round(comparison_df[\"optimized_score\"].mean(), 2),\n",
        "    \"Average Absolute Lift\": round(comparison_df[\"absolute_lift\"].mean(), 2),\n",
        "    \"Max Optimized Score\": comparison_df[\"optimized_score\"].max(),\n",
        "}\n",
        "\n",
        "pd.DataFrame(summary_metrics.items(), columns=[\"Metric\", \"Value\"])"
      ],
      "metadata": {
        "id": "AWiXvBonqmuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Comparison & Lift Analysis\n",
        "\n",
        "### Quantitative Results\n",
        "- The optimized semantic matching algorithm significantly outperforms\n",
        "  the baseline keyword-based approach.\n",
        "- Average match scores increased substantially across all student–faculty pairs.\n",
        "- Strong semantic matches that scored poorly in the baseline (e.g., \"ML\" vs\n",
        "  \"Machine Learning\") now receive high scores.\n",
        "\n",
        "### Key Improvements\n",
        "- Semantic understanding of skills and research areas\n",
        "- Robust handling of synonyms and related concepts\n",
        "- Better alignment with human intuition\n",
        "\n",
        "### Conclusion\n",
        "The optimized approach achieves a large absolute lift in match quality,\n",
        "demonstrating that LLM-assisted semantic embeddings are a superior choice\n",
        "for real-world academic matching systems.\n"
      ],
      "metadata": {
        "id": "iMub0HcZrRAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Conclusion\n",
        "\n",
        "The baseline Mentora matching algorithm provided a fast and explainable\n",
        "starting point but failed to capture semantic similarity.\n",
        "\n",
        "By integrating embedding-based semantic matching, the system achieved\n",
        "a significant improvement in match quality while remaining modular and extensible.\n",
        "\n",
        "This optimized approach can be further enhanced using:\n",
        "- Caching of embeddings\n",
        "- Hybrid exact + semantic matching\n",
        "- Threshold-based recommendations\n",
        "- Offline batch processing for scalability\n"
      ],
      "metadata": {
        "id": "YX3JD9tXreEu"
      }
    }
  ]
}